{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Networks.Network import Network\n",
    "from Utilities.utils import *\n",
    "from Utilities.experiment_utils import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['uci_id', 'name', 'repository_url', 'data_url', 'abstract', 'area', 'tasks', 'characteristics', 'num_instances', 'num_features', 'feature_types', 'demographics', 'target_col', 'index_col', 'has_missing_values', 'missing_values_symbol', 'year_of_dataset_creation', 'last_updated', 'dataset_doi', 'creators', 'intro_paper', 'additional_info'])\n"
     ]
    }
   ],
   "source": [
    "wine = fetch_ucirepo(name='Wine')\n",
    "print(wine.metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            name     role         type demographic  \\\n",
      "0                          class   Target  Categorical        None   \n",
      "1                        Alcohol  Feature   Continuous        None   \n",
      "2                      Malicacid  Feature   Continuous        None   \n",
      "3                            Ash  Feature   Continuous        None   \n",
      "4              Alcalinity_of_ash  Feature   Continuous        None   \n",
      "5                      Magnesium  Feature      Integer        None   \n",
      "6                  Total_phenols  Feature   Continuous        None   \n",
      "7                     Flavanoids  Feature   Continuous        None   \n",
      "8           Nonflavanoid_phenols  Feature   Continuous        None   \n",
      "9                Proanthocyanins  Feature   Continuous        None   \n",
      "10               Color_intensity  Feature   Continuous        None   \n",
      "11                           Hue  Feature   Continuous        None   \n",
      "12  0D280_0D315_of_diluted_wines  Feature   Continuous        None   \n",
      "13                       Proline  Feature      Integer        None   \n",
      "\n",
      "   description units missing_values  \n",
      "0         None  None             no  \n",
      "1         None  None             no  \n",
      "2         None  None             no  \n",
      "3         None  None             no  \n",
      "4         None  None             no  \n",
      "5         None  None             no  \n",
      "6         None  None             no  \n",
      "7         None  None             no  \n",
      "8         None  None             no  \n",
      "9         None  None             no  \n",
      "10        None  None             no  \n",
      "11        None  None             no  \n",
      "12        None  None             no  \n",
      "13        None  None             no  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(wine.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape (rows,cols): (178, 13)\n",
      "Target Shape (rows,cols): (178,)\n"
     ]
    }
   ],
   "source": [
    "X, y = wine.data.features, wine.data.targets.squeeze().to_numpy()\n",
    "print(f\"Dataset Shape (rows,cols): {X.shape}\")\n",
    "print(f\"Target Shape (rows,cols): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Number of samples in each dataset:\n",
      "Train shape: torch.Size([142, 13])\n",
      "Validation shape: torch.Size([8, 13])\n",
      "Test shape: torch.Size([28, 13])\n",
      "\n",
      "Shape of the target after one-hot encoding:\n",
      "Train shape: torch.Size([142, 3])\n",
      "Validation shape: torch.Size([8, 3])\n",
      "Test shape: torch.Size([28, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\predictive_analytics\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# random seed for train-test splits for reproducibility\n",
    "RANDOM_STATE = 1 \n",
    "\n",
    "# Since all input features are numerical, we can use the StandardScaler to normalize the data\n",
    "numerical_preprocessing = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_preprocessing, X.columns)\n",
    "])\n",
    "\n",
    "# Train, test, validation split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Preprocess the data and convert it to tensors\n",
    "X_train = torch.tensor(preprocessor.fit_transform(X_train), dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(preprocessor.transform(X_val), dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(preprocessor.transform(X_test), dtype=torch.float32).to(device)\n",
    "\n",
    "# One-hot encode the target\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = torch.tensor(encoder.fit_transform(y_train.reshape(-1, 1)), dtype=torch.long).to(device)\n",
    "y_val_encoded = torch.tensor(encoder.transform(y_val.reshape(-1, 1)), dtype=torch.long).to(device)\n",
    "y_test_encoded = torch.tensor(encoder.transform(y_test.reshape(-1, 1)), dtype=torch.long).to(device)\n",
    "\n",
    "# Data shapes\n",
    "print(\"Number of samples in each dataset:\")\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\"); print()\n",
    "\n",
    "# Target shapes\n",
    "print(\"Shape of the target after one-hot encoding:\")\n",
    "print(f\"Train shape: {y_train_encoded.shape}\")\n",
    "print(f\"Validation shape: {y_val_encoded.shape}\")\n",
    "print(f\"Test shape: {y_test_encoded.shape}\"); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL PARAMETERS ###\n",
    "RUN_EXPERIMENTS = False # if True run the experiments, else load the results from the results file\n",
    "EPOCHS = 400000 # maximum number of epochs to run, set to a large number to run until early stopping criterion is met\n",
    "\n",
    "# Set individual experiment parameters\n",
    "experiment_params = {\n",
    "    'experiment_1': {\n",
    "        'NUM_LAYERS': 1,\n",
    "        'NUM_INPUTS': X_train.shape[1],\n",
    "        'NUM_OUTPUTS': y_train_encoded.shape[1],\n",
    "        'params': {\n",
    "            'hidden_size': [[5], [10], [20]], # <---------------------------- change the hidden layer sizes here for experiment 1\n",
    "            'learning_rate': [1.0, 0.1, 0.01] # <---------------------------- change the learning rates here for experiment 1\n",
    "        }},\n",
    "    'experiment_2': {\n",
    "        'NUM_LAYERS': 2,\n",
    "        'NUM_INPUTS': X_train.shape[1],\n",
    "        'NUM_OUTPUTS': y_train_encoded.shape[1],\n",
    "        'params': {\n",
    "            'hidden_size': list(itertools.product([5, 10], repeat=2)), # <--- change the hidden layer sizes here for experiment 2\n",
    "            'learning_rate': [1.0, 0.1, 0.01] # <---------------------------- change the learning rates here for experiment 2\n",
    "        }},\n",
    "    'experiment_3': {\n",
    "        'NUM_LAYERS': 0,\n",
    "        'NUM_INPUTS': X_train.shape[1],\n",
    "        'NUM_OUTPUTS': y_train_encoded.shape[1],\n",
    "        'params': {\n",
    "            'hidden_size': [[]], # don't change this if you want no hidden layers\n",
    "            'learning_rate': [1.0, 0.1, 0.01] # <---------------------------- change the learning rates here for experiment 3\n",
    "        }},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    # Initialize the experimental results dictionary\n",
    "    experiments_dict = {\n",
    "        'experiment_1': [],\n",
    "        'experiment_2': [],\n",
    "        'experiment_3': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Network with One Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting local parameters\n",
    "NUM_LAYERS = experiment_params['experiment_1']['NUM_LAYERS']\n",
    "NUM_INPUTS = experiment_params['experiment_1']['NUM_INPUTS']\n",
    "NUM_OUTPUTS = experiment_params['experiment_1']['NUM_OUTPUTS']\n",
    "params = experiment_params['experiment_1']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    print(\"Running Experiments...\")\n",
    "\n",
    "    for hs in params['hidden_size']:\n",
    "\n",
    "        for lr in params['learning_rate']:\n",
    "            param_id = f\"hs={hs}_lr={lr}\"\n",
    "\n",
    "            # Create the model\n",
    "            model = Network(NUM_INPUTS, NUM_OUTPUTS, NUM_LAYERS, hs).to(device)\n",
    "\n",
    "            print(\"---------------------------------------------\")\n",
    "            print(f\"Hidden Layer Shape: {hs}; Learning Rate: {lr}\\n\")\n",
    "\n",
    "            # Train the model\n",
    "            model, train_loss, val_loss, train_cm, val_cm, epoch_stop, time = train_model(model, EPOCHS, lr, X_train, y_train_encoded, X_val, y_val_encoded, verbose=True)\n",
    "            training_accuracy = train_cm.diag().sum().float() / train_cm.sum().float()  \n",
    "            validation_accuracy = val_cm.diag().sum().float() / val_cm.sum().float()  \n",
    "            \n",
    "            print(f\"Training stopped at epoch {epoch_stop} after {time:.2f} seconds\\n\")\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_loss, test_cm = evaluate_model(model, X_test, y_test_encoded)\n",
    "            test_accuracy = (test_cm[0,0] + test_cm[1,1] + test_cm[2,2]) / torch.sum(test_cm)\n",
    "\n",
    "            results = {\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_cm': train_cm.cpu().numpy().tolist(),\n",
    "                'val_cm': val_cm.cpu().numpy().tolist(),\n",
    "                'training_accuracy': training_accuracy.cpu().numpy().tolist(),\n",
    "                'validation_accuracy': validation_accuracy.cpu().numpy().tolist(),\n",
    "                'training_time': time,\n",
    "                'epoch_stop': epoch_stop,\n",
    "                'test_loss': test_loss.cpu().numpy().tolist(),\n",
    "                'test_cm': test_cm.cpu().numpy().tolist(),\n",
    "                'test_accuracy': test_accuracy.cpu().numpy().tolist()\n",
    "            }\n",
    "\n",
    "            experiments_dict['experiment_1'].append({param_id: results})\n",
    "\n",
    "            print(\"Post-training Results:\")\n",
    "            print(f\"Train Loss: {train_loss[-1]:.4f}; Validation Loss: {val_loss[-1]:.4f}; Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"Training Accuracy: {training_accuracy:.4f}; Test Accuracy: {test_accuracy:.4f}\"); print()\n",
    "            print(f\"Train Confusion Matrix:\\n{train_cm}\"); print()\n",
    "            print(f\"Test Confusion Matrix:\\n{test_cm}\"); print()\n",
    "\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "    print(\"Experiments Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Network with Two Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting local parameters\n",
    "NUM_LAYERS = experiment_params['experiment_2']['NUM_LAYERS']\n",
    "NUM_INPUTS = experiment_params['experiment_2']['NUM_INPUTS']\n",
    "NUM_OUTPUTS = experiment_params['experiment_2']['NUM_OUTPUTS']\n",
    "params = experiment_params['experiment_2']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    print(\"Running Experiments...\")\n",
    "\n",
    "    for hs in params['hidden_size']:\n",
    "\n",
    "        for lr in params['learning_rate']:\n",
    "            param_id = f\"hs={hs}_lr={lr}\"\n",
    "\n",
    "            # Create the model\n",
    "            model = Network(NUM_INPUTS, NUM_OUTPUTS, NUM_LAYERS, hs).to(device)\n",
    "\n",
    "            print(\"---------------------------------------------\")\n",
    "            print(f\"Hidden Layer Shape: {hs}; Learning Rate: {lr}\\n\")\n",
    "\n",
    "            # Train the model\n",
    "            model, train_loss, val_loss, train_cm, val_cm, epoch_stop, time = train_model(model, EPOCHS, lr, X_train, y_train_encoded, X_val, y_val_encoded, verbose=True)\n",
    "            training_accuracy = train_cm.diag().sum().float() / train_cm.sum().float()  \n",
    "            validation_accuracy = val_cm.diag().sum().float() / val_cm.sum().float()\n",
    "            \n",
    "            print(f\"Training stopped at epoch {epoch_stop} after {time:.2f} seconds\\n\")\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_loss, test_cm = evaluate_model(model, X_test, y_test_encoded)\n",
    "            test_accuracy = (test_cm[0,0] + test_cm[1,1] + test_cm[2,2]) / torch.sum(test_cm)\n",
    "\n",
    "            results = {\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_cm': train_cm.cpu().numpy().tolist(),\n",
    "                'val_cm': val_cm.cpu().numpy().tolist(),\n",
    "                'training_accuracy': training_accuracy.cpu().numpy().tolist(),\n",
    "                'validation_accuracy': validation_accuracy.cpu().numpy().tolist(),\n",
    "                'training_time': time,\n",
    "                'epoch_stop': epoch_stop,\n",
    "                'test_loss': test_loss.cpu().numpy().tolist(),\n",
    "                'test_cm': test_cm.cpu().numpy().tolist(),\n",
    "                'test_accuracy': test_accuracy.cpu().numpy().tolist()\n",
    "            }\n",
    "\n",
    "            experiments_dict['experiment_2'].append({param_id: results})\n",
    "\n",
    "            print(\"Post-training Results:\")\n",
    "            print(f\"Train Loss: {train_loss[-1]:.4f}; Validation Loss: {val_loss[-1]:.4f}; Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"Training Accuracy: {training_accuracy:.4f}; Test Accuracy: {test_accuracy:.4f}\"); print()\n",
    "            print(f\"Train Confusion Matrix:\\n{train_cm}\"); print()\n",
    "            print(f\"Test Confusion Matrix:\\n{test_cm}\"); print()\n",
    "\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "    print(\"Experiments Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Model with 0 Hidden Layers (Linear Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting local parameters\n",
    "NUM_LAYERS = experiment_params['experiment_3']['NUM_LAYERS']\n",
    "NUM_INPUTS = experiment_params['experiment_3']['NUM_INPUTS']\n",
    "NUM_OUTPUTS = experiment_params['experiment_3']['NUM_OUTPUTS']\n",
    "params = experiment_params['experiment_3']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    print(\"Running Experiments...\")\n",
    "\n",
    "    for hs in params['hidden_size']:\n",
    "\n",
    "        for lr in params['learning_rate']:\n",
    "            param_id = f\"hs={hs}_lr={lr}\"\n",
    "\n",
    "            # Create the model\n",
    "            model = Network(NUM_INPUTS, NUM_OUTPUTS, NUM_LAYERS, hs).to(device)\n",
    "\n",
    "            print(\"---------------------------------------------\")\n",
    "            print(f\"Hidden Layer Shape: {hs}; Learning Rate: {lr}\\n\")\n",
    "\n",
    "            # Train the model\n",
    "            model, train_loss, val_loss, train_cm, val_cm, epoch_stop, time = train_model(model, EPOCHS, lr, X_train, y_train_encoded, X_val, y_val_encoded, verbose=True)\n",
    "            training_accuracy = train_cm.diag().sum().float() / train_cm.sum().float()  \n",
    "            validation_accuracy = val_cm.diag().sum().float() / val_cm.sum().float()\n",
    "            \n",
    "            print(f\"Training stopped at epoch {epoch_stop} after {time:.2f} seconds\\n\")\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_loss, test_cm = evaluate_model(model, X_test, y_test_encoded)\n",
    "            test_accuracy = (test_cm[0,0] + test_cm[1,1] + test_cm[2,2]) / torch.sum(test_cm)\n",
    "\n",
    "            results = {\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_cm': train_cm.cpu().numpy().tolist(),\n",
    "                'val_cm': val_cm.cpu().numpy().tolist(),\n",
    "                'training_accuracy': training_accuracy.cpu().numpy().tolist(),\n",
    "                'validation_accuracy': validation_accuracy.cpu().numpy().tolist(),\n",
    "                'training_time': time,\n",
    "                'epoch_stop': epoch_stop,\n",
    "                'test_loss': test_loss.cpu().numpy().tolist(),\n",
    "                'test_cm': test_cm.cpu().numpy().tolist(),\n",
    "                'test_accuracy': test_accuracy.cpu().numpy().tolist()\n",
    "            }\n",
    "\n",
    "            experiments_dict['experiment_3'].append({param_id: results})\n",
    "\n",
    "            print(\"Post-training Results:\")\n",
    "            print(f\"Train Loss: {train_loss[-1]:.4f}; Validation Loss: {val_loss[-1]:.4f}; Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"Training Accuracy: {training_accuracy:.4f}; Test Accuracy: {test_accuracy:.4f}\"); print()\n",
    "            print(f\"Train Confusion Matrix:\\n{train_cm}\"); print()\n",
    "            print(f\"Test Confusion Matrix:\\n{test_cm}\"); print()\n",
    "\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "    print(\"Experiments Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    filename = 'Results/experiments.json'\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(experiments_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were multiple models with perfect accuracy, showing the one with the lowest test loss of that set\n",
      "Model with param_id: hs=(10, 5)_lr=1.0 with a test accuracy of 1.0000 had the lowest test loss of 0.0006\n",
      "Best Model Test Confusion Matrix:\n",
      "[[11  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "if not RUN_EXPERIMENTS:\n",
    "\n",
    "    try:\n",
    "        with open('Results/experiments.json', 'r') as f:\n",
    "            experiments_dict = json.load(f)\n",
    "    except:\n",
    "        print(\"No experiments file found. Please ensure experiments.json exists.\")\n",
    "        sys.exit()\n",
    "        \n",
    "    best_experiment, best_param_id, best_accuracy, best_loss, multi_best_acc = find_best_model(experiments_dict)\n",
    "\n",
    "    if multi_best_acc:\n",
    "        print(\"There were multiple models with perfect accuracy, showing the one with the lowest test loss of that set\")\n",
    "        print(f\"Model with param_id: {best_param_id} with a test accuracy of {best_accuracy:.4f} had the lowest test loss of {best_loss:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"Best model had param_id: {best_param_id} with a test accuracy of {best_accuracy:.4f} and test loss of {best_loss:.4f}\\n\")\n",
    "\n",
    "    # Show the test confusion matrix of the best model\n",
    "    found = False  # Flag to indicate if the best model has been found\n",
    "    for experiment in experiments_dict[best_experiment]:\n",
    "        if found:\n",
    "            break  # Exit outer loop if best model was found\n",
    "        for current_param_id, result in experiment.items():\n",
    "            if current_param_id == best_param_id:\n",
    "                print(\"Best Model Test Confusion Matrix:\")\n",
    "                print(np.array(result['test_cm']))\n",
    "                found = True  # Set flag to true and break inner loop\n",
    "                break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
